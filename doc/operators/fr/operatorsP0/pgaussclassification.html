<html>
<head>
<title>OPERATEURS PANDORE</title>
<style>
body { padding: 1em 1em 1em 30px; }
</style>
</head>

<body background="#ffffff">
<center>
<table border=0 width=100%>
<tr>
<td align=left width=50%><b><i>PANDORE Version 6</i></b></td>
<td align=right width=50%><b><i>GREYC-IMAGE</i></b></td></tr></table>
</center>
<hr>

<!---------------------------------- -->
<h1>pgaussclassification</h1>
<!---------------------------------- -->
<hr noshade size=1 width=100 align=left><br>

Classification utilisant un mod&egrave;le gaussien.

<br><br><hr noshade size=1 width=100 align=left><br>

<!---------------------------------- -->
<h3>Synopsis</h3>
<!---------------------------------- -->
<tt>
<b>pgaussclassification</b> <i>attr_base</i> <i>attr_in</i> <i>attr_out</i> [<i>col_base</i>|-] [<i>col_in</i>|-] [<i>col_out</i>|-]
</tt>

<!---------------------------------- -->
<h3>Description</h3>
<!---------------------------------- -->
<p>L'op&eacute;rateur <tt>pgaussclassification</tt> impl&eacute;mente une
classification bas&eacute;e sur un mod&egrave;le gaussien.
L'id&eacute;e. est de mod&eacute;liser la distribution de chaque
classe par une gaussienne,<br>
puis pour un  x donn&eacute; de
rechercher la classe qui maximise la probabilit&eacute; de contenir x.
Pratiquement, <tt>pgaussclassification</tt> cherche la classe <tt>i</tt> 
qui minimise:</p>
<pre>                                                            
  f(x,i) = ln(det A(i)) + <sup>t</sup>(x - m(i)).A(i)<sup>-1</sup>.(x - m(i)) - ln(P(i)<sup>2</sup>)
</pre>
<ul>
<li> <tt>x</tt> est le vecteur de caract&eacute;ristiques 
     repr&eacute;sentant l' &agrave; classifier ;
<li> <tt>A(i)</tt> la matrice de covariance associ&eacute;e
     &agrave; la classe <tt>i</tt> ;
<li> <tt>m(i)</tt> le vecteur de moyennes des caract&eacute;ristiques 
     de la classe <tt>i</tt> ;
<li> <tt>P(i)</tt> la probabilit&eacute; <i>a priori</i> de 
     trouver la classe <tt>i</tt>.
</ul>

<!---------------------------------- -->
<h3>Param&egrave;tres</h3>
<!---------------------------------- -->
<ul>
<li>La collection <tt>col_base</tt> doit contenir les param&egrave;tres
     de la formule ci-dessus.<br>Si l'on suppose qu'il existe n classes et
     p caract&eacute;ristiques par &eacute;l&eacute;ment :
     <ul>
     <li> <tt>attr_base.moy</tt> est un tableau de <tt>n*p</tt> flottants 
          contenant &agrave; l'indice [<tt>i*n+j</tt>] la moyenne de la 
          (<tt>j+1</tt>)i&egrave;me caract&eacute;ristique de la 
          (<tt>i+1</tt>) classe.
     <li> <tt>attr_base.det</tt> est un tableau de n flottants contenant
          &agrave; l'indice [<tt>i-1</tt>] la valeur de <tt>det(A(i))</tt>.
     <li> <tt>attr_base.inv</tt> est le tableau des matrices <tt>A^(-1)</tt>; 
          l'indice [<tt>k*p*p + i*p +j</tt>] correspond &agrave; la cellule
          <tt>(i+1,j+1)</tt> de la <tt>(k+1)</tt>i&egrave;me matrice.
     </ul>

     (Ces trois 3 attributs peuvent &ecirc;tre calcul&eacute;s 
     avec l'op&eacute;rateur <a href="parraycovarmat.html">parraycovarmat</a>.)
     <ul>
     <li> <tt>attr_base.pap</tt> est le tableau des probabilit&eacute;s
          <i>a priori</i> pour chaque classe (un tableau de <tt>n</tt>
	  flottants donc).
     </ul> 
     (Ce dernier attribut peut-&ecirc;tre omis, dans le cas o&ugrave; les classes sont 
     &eacute;quiprobables.)
<li>La collection <tt>col_in</tt> doit contenir les <tt>x</tt> &agrave; classifier,
     sous la forme d'attributs<br>
     <tt>attr_in.1</tt>, <tt>attr_in.2</tt>, 
     ..., <tt>attr_in.p</tt>,<br>
     qui sont des tableaux contenant les
     caract&eacute;ristiques de chaque &eacute;l&eacute;ment &agrave; classifier.

<li>La collection <tt>col_out</tt> contient un tableau de Ushort, donnant
     la classe d&eacute;termin&eacute;e pour chaque 
     de <tt>col_in</tt>.

</ul>

<!---------------------------------- -->
<h3>Entr&eacute;es</h3>
<!---------------------------------- -->
<ul>
<li><i>col_base</i>: une collection contenant les param&egrave;tres appris.
<li><i>col_in</i>: une collection &agrave; classer.
</ul>

<!---------------------------------- -->
<h3>Sorties</h3>
<!---------------------------------- -->
<ul>
<li><i>col_out</i>: une collection.
</ul>

<!---------------------------------- -->
<h3>R&eacute;sultat</h3>
<!---------------------------------- -->
<p>Retourne SUCCESS ou FAILURE.</p>

<!---------------------------------- -->
<h3>Exemples</h3>
<!---------------------------------- -->
<p>Classification des bonbons de l'image jellybean.pan &agrave; partir d'un &eacute;chantillon des diff&eacute;rents types de bonbons stock&eacute;s dans le dossier 'base' (Unix version):</p>
<pre>
# Learning
classes=1
for i in base/*.pan
do
    pim2array ind $i /tmp/tmp1 
    parray2array ind.1 Float /tmp/tmp1| parray2array ind.2 Float | parray2array ind.3 Float - a.pan
    parraycovarmat ind ind a.pan i-01.pan
    if [ -f base.pan ]
    then pcolcatenateitem i-01.pan base.pan base.pan
    else cp i-01.pan base.pan
    fi
    classe=`expr $classe + 1`
done
rm /tmp/tmp1

# Classification
pim2array ind jellybeans.pan a.pan
parray2array ind.1 Float a.pan| parray2array ind.2 Float | parray2array ind.3 Float - b.pan
pgaussclassification ind ind ind base.pan b.pan | parray2im $ncol $nrow 0 ind | pim2rg - out.pan
</pre>

<!---------------------------------- -->
<h3>Voir aussi</h3>
<!---------------------------------- -->
<a href="../operatorsP0.html#classification">Classification</a>

<!---------------------------------- -->
<h3>Prototype C++</h3>
<!---------------------------------- -->
<tt>
Errc PGaussClassification(const std::string &amp;a_base,  const Collection &amp;c_base,
		const std::string &amp;a_in,    const Collection &amp;c_in,
		const std::string &amp;a_out,         Collection &amp;c_out);
</tt>


<hr>
<p>
<!---------------------------------- -->
<address>
Auteur: Alexandre Duret-Lutz
</address>
<!---------------------------------- -->
</body>
</html>