<html>
<head>
<title>PANDORE OPERATORS</title>
<style>
body { padding: 1em 1em 1em 30px; }
</style>
</head>

<body background="#ffffff">
<center>
<table border=0 width=100%>
<tr>
<td align=left width=50%><b><i>PANDORE Version 6</i></b></td>
<td align=right width=50%><b><i>GREYC-IMAGE</i></b></td></tr></table>
</center>
<hr>

<!---------------------------------- -->
<h1>pgaussclassification</h1>
<!---------------------------------- -->
<hr noshade size=1 width=100 align=left><br>

Performs gauss clustering on a set of objects.

<br><br><hr noshade size=1 width=100 align=left><br>

<!---------------------------------- -->
<h3>Synopsis</h3>
<!---------------------------------- -->
<tt>
<b>pgaussclassification</b> <i>attr_base</i> <i>attr_in</i> <i>attr_out</i> [<i>col_base</i>|-] [<i>col_in</i>|-] [<i>col_out</i>|-]
</tt>

<!---------------------------------- -->
<h3>Description</h3>
<!---------------------------------- -->
<p><b>pgaussclassification</b> is a partitioning method for a group of n objects
into <i>k</i> clusters.
The basic idea supposes that the class distribution has a gaussian distribution,
and for each object x to be classified the principle is to find the class that has
the maximum probability to contain x.</p>

<p>Practically, <tt>pgaussclassification</tt> finds the class <tt>i</tt> that
minimizes:</p>
<pre>                                                            
   f(x,i) = ln(det A(i)) + <sup>t</sup>(x - m(i)).A(i)<sup>-1</sup>.(x - m(i)) - ln(P(i)<sup>2</sup>)
</pre>
<ul>
<li>where <tt>x</tt> is the feature vector for the object x;
<li> <tt>A(i)</tt> is the covariance matrix for the class <tt>i</tt> ;
<li> <tt>m(i)</tt> is mean vector the for class <tt>i</tt> ;
<li> <tt>P(i)</tt> is the a priori probability to find class <tt>i</tt>.
</ul>

<p>These values can be calculated from the operator <a href="./parraycovarmat.html">parraycovarmat</a>.

<!---------------------------------- -->
<h3>Parameters</h3>
<!---------------------------------- -->
<ul>
<li><i>attr_base</i> is the base name for the gaussian features.
If there exists n clusters and p features:
    <ul>
    <li><tt>attr_base.mean</tt> is an array of <tt>n*p</tt> values which contains
at the index [<tt>i*n+j</tt>] the mean of the <tt>j+1</tt>th feature of
the <tt>i-1</tt> cluster.

    <li><tt>attr_base.det</tt> is an array of n reals which contains at the index
[<tt>i-1</tt>] the determinant <tt>det(A(i))</tt>.

    <li><tt>attr_base.inv</tt> is an array of <tt>p*p</tt> values which
contains at the index [<tt>k*p*p + i*p +j</tt>] the value of <tt>k-1</tt>th matrix
cell of the A<sup>-1</sup>[i,j].
     (These 3 attributes can be calculted thanks to the operator
     <a href="parraycovarmat.html">parraycovarmat</a>.)
    <tt>attr_base.pap</tt> is an array of n reals which contains
a priori probabilities of each cluster. (This array can be omitted;
in this case probabilities are supposed equiprobable).
     </ul> 

<li><i>attr_in</i> is the base name of the feature vector of the objects
to be classified. The vectors
are named <tt>attr_in.1</tt>, <tt>attr_in.2</tt>, ..., <tt>attr_in.n</tt> in the input collection.
The item j of the array  <tt>attr_in.i</tt> contains the (i)th
feature of the (j+1)th object. They are Double arrays.

<li><i>attr_out</i> is the name of the output array. Each item
i of the array contains the cluster index from which the
(i)th object is assigned. <i>attr_out</i> is an array of
unsigned longs where attr_out[i] specifies the cluster index for
the object i.
</ul>

<!---------------------------------- -->
<h3>Inputs</h3>
<!---------------------------------- -->
<ul>
<li><i>col_base</i>: a collection which contains the learned parameters.
<li><i>col_in</i>: a collection which contains the objects to be classified.
</ul>

<!---------------------------------- -->
<h3>Outputs</h3>
<!---------------------------------- -->
<ul>
<li><i>col_out</i>: a collection which contains classified objects.
</ul>

<!---------------------------------- -->
<h3>Result</h3>
<!---------------------------------- -->
<p>Returns SUCCESS or FAILURE.</p>

<!---------------------------------- -->
<h3>Examples</h3>
<!---------------------------------- -->
<p>Classifies beans into the jellybean.pan image from sample
of each bean stored in the directory 'base' (Unix version).</p>
<pre>
# Learning
classes=1
for i in base/*.pan
do
    pim2array ind $i /tmp/tmp1 
    parray2array ind.1 Float /tmp/tmp1| parray2array ind.2 Float | parray2array ind.3 Float - a.pan
    parraycovarmat ind ind a.pan i-01.pan
    if [ -f base.pan ]
    then pcolcatenateitem i-01.pan base.pan base.pan
    else cp i-01.pan base.pan
    fi
    classe=`expr $classe + 1`
done
rm /tmp/tmp1

# Classification
pim2array ind jellybeans.pan a.pan
parray2array ind.1 Float a.pan| parray2array ind.2 Float | parray2array ind.3 Float - b.pan
pgaussclassification ind ind ind base.pan b.pan | parray2im $ncol $nrow 0 ind | pim2rg - out.pan
</pre>

<!---------------------------------- -->
<h3>See also</h3>
<!---------------------------------- -->
<a href="../operatorsP0.html#classification">Classification</a>

<!---------------------------------- -->
<h3>C++ prototype</h3>
<!---------------------------------- -->
<tt>
Errc PGaussClassification(const std::string &amp;a_base,  const Collection &amp;c_base,
		const std::string &amp;a_in,    const Collection &amp;c_in,
		const std::string &amp;a_out,         Collection &amp;c_out);
</tt>

<!---------------------------------- -->
<h3>Version fran&ccedil;aise</h3>
<!---------------------------------- -->
<p>Classification utilisant un mod&egrave;le gaussien.</p>

<hr>
<p>
<!---------------------------------- -->
<address>
Author: Alexandre Duret-Lutz
</address>
<!---------------------------------- -->
</body>
</html>